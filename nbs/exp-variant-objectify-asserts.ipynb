{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otázky\n",
    "\n",
    "1. když provedu `single_correction`, mám vrátit tu korekci a pak teprve\n",
    " updatovat hyperparametry? Dává to smysl, jinak by vyšlo několikrát to samé..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import common\n",
    "from exp_family import update_IW, init_IW_hyp, get_IW_pars_from_hyp\n",
    "import exp_family\n",
    "from typing import Tuple\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix = np.ndarray\n",
    "MultiShape = np.ndarray\n",
    "Scalar = np.number\n",
    "Vector = np.ndarray\n",
    "\n",
    "class IWPrior:\n",
    "    hp: MultiShape = None\n",
    "    p: Scalar = None\n",
    "    \n",
    "    def __init__(self, nu: Scalar, psi: Matrix):\n",
    "        self.hp = np.array([\n",
    "            -0.5 * psi, \n",
    "            -0.5 * (nu + psi.shape[0] + 1)\n",
    "        ])\n",
    "    \n",
    "    @property\n",
    "    def psi(self) -> Matrix:\n",
    "        return -2 * self.hp[0]\n",
    "    \n",
    "    @property\n",
    "    def nu(self) -> Scalar:\n",
    "        return -2 * self.hp[1] - self.p - 1\n",
    "    \n",
    "    @property\n",
    "    def p(self) -> int:\n",
    "        return self.hp[0].shape[0]\n",
    "    \n",
    "    def expect(self):\n",
    "        return self.psi / (self.nu - self.p - 1)\n",
    "    \n",
    "class MeasurementNode:\n",
    "    P_prior: IWPrior = None\n",
    "    R_prior: IWPrior = None\n",
    "    F: Matrix = None\n",
    "    Q: Matrix = None\n",
    "    last_state: Vector = None\n",
    "        \n",
    "    logger = defaultdict(list)\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x: Vector,\n",
    "                 P_prior: IWPrior,\n",
    "                 R_prior: IWPrior,\n",
    "                 F: Matrix,\n",
    "                 Q: Matrix,\n",
    "                 H: Matrix,\n",
    "                 rho: Scalar,\n",
    "                 tau: Scalar,\n",
    "                 N = 10,\n",
    "                ):\n",
    "        self.last_state = x\n",
    "        self.P_prior = P_prior\n",
    "        self.R_prior = R_prior\n",
    "        self.F = F\n",
    "        self.Q = Q\n",
    "        self.H = H\n",
    "        self.rho = rho\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.P = self.P_prior.expect()\n",
    "        \n",
    "    def predict_state(self) -> Tuple[Vector, Matrix]:\n",
    "        return common.time_update(self.last_state, self.P, self.F, self.Q)\n",
    "    \n",
    "    def _single_update(self, state_prediction, P_prediction, measurement,\n",
    "                     init_hyp_P, init_hyp_R):\n",
    "        x = state_prediction\n",
    "        P = P_prediction\n",
    "        for i in range(N):\n",
    "            R, hyp_R = update_IW(init_hyp_R, \n",
    "                                 measurement, \n",
    "                                 self.H @ x, \n",
    "                                 self.H @ P @ self.H.T)\n",
    "            P, hyp_P = update_IW(init_hyp_P, x, state_prediction, P)\n",
    "            P, x = common.kalman_correction(H, P, R, state_prediction, measurement)\n",
    "        return x, P, hyp_P, hyp_R\n",
    "    \n",
    "    def _init_hyp_P(self, P_predicted):\n",
    "        init = exp_family.init_P_hyp(self.tau, P_predicted)\n",
    "        return init\n",
    "    \n",
    "    \n",
    "    def _init_hyp_R(self):\n",
    "        init = exp_family.init_R_hyp(self.rho, self.R_prior.psi, self.R_prior.nu)\n",
    "        return init\n",
    "    \n",
    "    \n",
    "    def _single_kf(self, measurement):\n",
    "        x_predicted, P_predicted = self.predict_state()\n",
    "        init_hyp_P = self._init_hyp_P(P_predicted)\n",
    "        init_hyp_R = self._init_hyp_R()\n",
    "        return self._single_update(x_predicted, P_predicted, measurement,\n",
    "                                  init_hyp_P, init_hyp_R)\n",
    "    \n",
    "    def single_kf(self, measurement):\n",
    "        x, P, hyp_P, hyp_R = self._single_kf(measurement)\n",
    "        self.last_state = x\n",
    "        self.P = P\n",
    "        self.P_prior.hp = hyp_P\n",
    "        self.R_prior.hp = hyp_R\n",
    "        \n",
    "    def log(self, key, val):\n",
    "        self.logger[key].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_factory(x, P, u, U, F, Q, H, rho, tau):\n",
    "    P_p = IWPrior(P.shape[0] + tau + 1, tau * P)\n",
    "    R_p = IWPrior(u, U)    \n",
    "    return MeasurementNode(x, P_p, R_p, F, Q, H, rho, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj, xk, P, tau, rho, u, U, H, F, Q, N = common.init_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = node_factory(xk, P, u, U, F, Q, H, rho, tau)\n",
    "m2 = node_factory(xk, P, u, U, F, Q, H, rho, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.predict_state()\n",
    "m1.single_kf(traj.Y.T[0])\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj, xk, P, tau, rho, u, U, H, F, Q, N = common.init_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "x_log = []\n",
    "P_log = []\n",
    "for zk in traj.Y.T:\n",
    "    #print('===== Step: ', t, '======') \n",
    "    t += 1\n",
    "    m1 = node_factory(xk, P, u, U, F, Q, H, rho, tau)\n",
    "    #### Time update\n",
    "    # xkl\n",
    "    xk = common.predict_state(F, xk)  # xll\n",
    "    # Pkl\n",
    "    P = common.predict_PECM(F, P, Q)  # Pll\n",
    "    assert np.isclose(xk, m1.predict_state()[0]).all() \n",
    "    assert np.isclose(P, m1.predict_state()[1]).all().all()\n",
    "    \n",
    "    #### Measurement update\n",
    "    ## Initialization - step 3\n",
    "    # Pikk\n",
    "    Pik = P\n",
    "    # xikk\n",
    "    xikk = xk\n",
    "    \n",
    "    # tkl, Tkl, ukl, Ukl \n",
    "    tkk, Tkk, ukl, Ukl = common.init(P, tau, P.shape[0], rho, u, U.shape[0], U)\n",
    "    \n",
    "    hyp_P = init_IW_hyp(Tkk, tkk)\n",
    "    hyp_P_prev = hyp_P.copy()\n",
    "    \n",
    "    hyp_R = init_IW_hyp(Ukl, ukl)\n",
    "    hyp_R_prev = hyp_R.copy()\n",
    "    ## END of Initialization - step 3\n",
    "    \n",
    "    assert hyp_P[1] == m1._init_hyp_P(P)[1]\n",
    "    assert np.isclose(hyp_P[0], m1._init_hyp_P(P)[0]).all().all()\n",
    "    \n",
    "\n",
    "    #assert hyp_R[1] == m1._init_hyp_R()[1]\n",
    "    assert hyp_R[1] == m1._init_hyp_R()[1]\n",
    "    assert np.isclose(hyp_R[0], m1._init_hyp_R()[0]).all().all()\n",
    "\n",
    "    \n",
    "    ## VB iters\n",
    "    for i in range(N):\n",
    "        Rjk, hyp_R = update_IW(hyp_R_prev, zk, H @ xikk, H @ Pik @ H.T)\n",
    "        Pjkl, hyp_P = update_IW(hyp_P_prev, xikk, xk, Pik)\n",
    "        # Pjkk, xjkk\n",
    "        Pik, xikk = common.kalman_correction(H, Pjkl, Rjk, xk, zk)\n",
    "    \n",
    "    # Assignment - step 13\n",
    "    # xkk\n",
    "    xk = xikk\n",
    "    # Pkk\n",
    "    P = Pik\n",
    "    # ukk, Ukk\n",
    "    U, u = get_IW_pars_from_hyp(hyp_R)\n",
    "    #P, p = get_IW_pars_from_hyp(hyp_P)\n",
    "    x_, P_, *_ = m1._single_kf(zk)\n",
    "    assert np.isclose(xk, x_).all()\n",
    "    assert np.isclose(P, P_).all().all()\n",
    "    \n",
    "    x_log.append(xk)\n",
    "    P_log.append(P)\n",
    "    \n",
    "x_log = np.array(x_log).squeeze().T\n",
    "P_log = np.array(P_log).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "x_log = []\n",
    "P_log = []\n",
    "for zk in traj.Y.T:\n",
    "    #print('===== Step: ', t, '======') \n",
    "    t += 1\n",
    "    m1 = node_factory(xk, P, u, U, F, Q, H, rho, tau)\n",
    "    #### Time update\n",
    "    # xkl\n",
    "    xk = common.predict_state(F, xk)  # xll\n",
    "    # Pkl\n",
    "    P = common.predict_PECM(F, P, Q)  # Pll\n",
    "    assert np.isclose(xk, m1.predict_state()[0]).all() \n",
    "    assert np.isclose(P, m1.predict_state()[1]).all().all()\n",
    "    \n",
    "    #### Measurement update\n",
    "    ## Initialization - step 3\n",
    "    # Pikk\n",
    "    Pik = P\n",
    "    # xikk\n",
    "    xikk = xk\n",
    "    \n",
    "    # tkl, Tkl, ukl, Ukl \n",
    "    tkk, Tkk, ukl, Ukl = common.init(P, tau, P.shape[0], rho, u, U.shape[0], U)\n",
    "    \n",
    "    hyp_P = init_IW_hyp(Tkk, tkk)\n",
    "    hyp_P_prev = hyp_P.copy()\n",
    "    \n",
    "    hyp_R = init_IW_hyp(Ukl, ukl)\n",
    "    hyp_R_prev = hyp_R.copy()\n",
    "    ## END of Initialization - step 3\n",
    "    \n",
    "    assert hyp_P[1] == m1._init_hyp_P(P)[1]\n",
    "    assert np.isclose(hyp_P[0], m1._init_hyp_P(P)[0]).all().all()\n",
    "    \n",
    "\n",
    "    #assert hyp_R[1] == m1._init_hyp_R()[1]\n",
    "    assert hyp_R[1] == m1._init_hyp_R()[1]\n",
    "    assert np.isclose(hyp_R[0], m1._init_hyp_R()[0]).all().all()\n",
    "\n",
    "    \n",
    "    ## VB iters\n",
    "    for i in range(N):\n",
    "        Rjk, hyp_R = update_IW(hyp_R_prev, zk, H @ xikk, H @ Pik @ H.T)\n",
    "        Pjkl, hyp_P = update_IW(hyp_P_prev, xikk, xk, Pik)\n",
    "        # Pjkk, xjkk\n",
    "        Pik, xikk = common.kalman_correction(H, Pjkl, Rjk, xk, zk)\n",
    "    \n",
    "    # Assignment - step 13\n",
    "    # xkk\n",
    "    xk = xikk\n",
    "    # Pkk\n",
    "    P = Pik\n",
    "    # ukk, Ukk\n",
    "    U, u = get_IW_pars_from_hyp(hyp_R)\n",
    "    #P, p = get_IW_pars_from_hyp(hyp_P)\n",
    "    x_, P_, *_ = m1._single_kf(zk)\n",
    "    assert np.isclose(xk, x_).all()\n",
    "    assert np.isclose(P, P_).all().all()\n",
    "    \n",
    "    x_log.append(xk)\n",
    "    P_log.append(P)\n",
    "    \n",
    "x_log = np.array(x_log).squeeze().T\n",
    "P_log = np.array(P_log).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4619606664283383, 0.7668096325216082)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KF, just measurements\n",
    "np.sqrt(((x_log[:2] - traj.X[:2]) ** 2 ).mean()), np.sqrt(((traj.Y[:2] - traj.X[:2]) ** 2 ).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.246633480261624"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# velocity: KF\n",
    "np.sqrt(((x_log[2:] - traj.X[2:]) ** 2 ).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kalman",
   "language": "python",
   "name": "kalman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
